{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2cc312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üî• R√âENTRA√éNEMENT DU MOD√àLE LOGISTICREGRESSION\n",
      "======================================================================\n",
      "\n",
      "üì¶ 1. CHARGEMENT DES DONN√âES COMPL√àTES\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Donn√©es charg√©es: 5572 messages\n",
      "   ‚Ä¢ HAM: 4825 messages\n",
      "   ‚Ä¢ SPAM: 747 messages\n",
      "\n",
      "üßπ 2. NETTOYAGE DU TEXTE\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Texte nettoy√©\n",
      "\n",
      "üî§ 3. VECTORISATION TF-IDF\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ TF-IDF cr√©√©: 1000 features\n",
      "\n",
      "üî¢ 4. EXTRACTION DES FEATURES NUM√âRIQUES\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Features num√©riques extraites: 16 features\n",
      "\n",
      "üîó 5. COMBINAISON DES FEATURES\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Features combin√©es: 1016 features total\n",
      "   ‚Ä¢ TF-IDF: 1000\n",
      "   ‚Ä¢ Num√©riques: 16\n",
      "   ‚Ä¢ Cibles: 5572\n",
      "\n",
      "üìä 6. SPLIT DES DONN√âES\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Split termin√©:\n",
      "   ‚Ä¢ Train: 4457 √©chantillons\n",
      "   ‚Ä¢ Test: 1115 √©chantillons\n",
      "\n",
      "ü§ñ 7. ENTRA√éNEMENT DU MOD√àLE LOGISTICREGRESSION\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Mod√®le entra√Æn√©\n",
      "\n",
      "üìà 8. √âVALUATION DU MOD√àLE\n",
      "----------------------------------------------------------------------\n",
      "üìä PERFORMANCES:\n",
      "   ‚Ä¢ Accuracy (train): 97.35%\n",
      "   ‚Ä¢ Accuracy (test):  97.31%\n",
      "   ‚Ä¢ Precision:        86.50%\n",
      "   ‚Ä¢ Recall:           94.63%\n",
      "   ‚Ä¢ F1-Score:         90.38%\n",
      "\n",
      "üìã RAPPORT DE CLASSIFICATION:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HAM       0.99      0.98      0.98       966\n",
      "        SPAM       0.87      0.95      0.90       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.93      0.96      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "üíæ 9. SAUVEGARDE DES MOD√àLES\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Mod√®le sauvegard√©: models/logistic_regression_model_final.joblib\n",
      "‚úÖ Vectorizer sauvegard√©: models/tfidf_vectorizer_final.joblib\n",
      "‚úÖ Label encoder sauvegard√©: models/label_encoder_final.joblib\n",
      "\n",
      "üß™ 10. TESTS DE PR√âDICTION\n",
      "----------------------------------------------------------------------\n",
      "üìù Tests de pr√©diction:\n",
      "----------------------------------------\n",
      "üì® 'Congratulations! You won a free iPhone! Call now t...'\n",
      "   ‚Üí Pr√©dit: SPAM (97.36%)\n",
      "   ‚Üí Attendu: SPAM\n",
      "   ‚Üí ‚úÖ CORRECT\n",
      "\n",
      "üì® 'Hey, are we still meeting for lunch tomorrow?...'\n",
      "   ‚Üí Pr√©dit: HAM (2.52%)\n",
      "   ‚Üí Attendu: HAM\n",
      "   ‚Üí ‚úÖ CORRECT\n",
      "\n",
      "üì® 'URGENT: Your bank account has been compromised....'\n",
      "   ‚Üí Pr√©dit: SPAM (59.79%)\n",
      "   ‚Üí Attendu: SPAM\n",
      "   ‚Üí ‚úÖ CORRECT\n",
      "\n",
      "üì® 'Don't forget to buy milk on your way home...'\n",
      "   ‚Üí Pr√©dit: HAM (1.09%)\n",
      "   ‚Üí Attendu: HAM\n",
      "   ‚Üí ‚úÖ CORRECT\n",
      "\n",
      "üì® 'FREE entry to win ¬£1000 cash prize. Text WIN now!...'\n",
      "   ‚Üí Pr√©dit: SPAM (99.83%)\n",
      "   ‚Üí Attendu: SPAM\n",
      "   ‚Üí ‚úÖ CORRECT\n",
      "\n",
      "üì® 'Meeting rescheduled to 3 PM. See you then....'\n",
      "   ‚Üí Pr√©dit: HAM (4.46%)\n",
      "   ‚Üí Attendu: HAM\n",
      "   ‚Üí ‚úÖ CORRECT\n",
      "\n",
      "\n",
      "üåê 11. MISE √Ä JOUR DE L'API\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ API mise √† jour avec le nouveau mod√®le\n",
      "\n",
      "======================================================================\n",
      "üéâ R√âENTRA√éNEMENT TERMIN√â !\n",
      "======================================================================\n",
      "\n",
      "üìä PERFORMANCES FINALES:\n",
      "   ‚Ä¢ Accuracy:  97.31%\n",
      "   ‚Ä¢ F1-Score:  90.38%\n",
      "\n",
      "üìÅ MOD√àLES SAUVEGARD√âS:\n",
      "   ‚Ä¢ logistic_regression_model_final.joblib\n",
      "   ‚Ä¢ tfidf_vectorizer_final.joblib\n",
      "   ‚Ä¢ label_encoder_final.joblib\n",
      "\n",
      "üöÄ POUR TESTER:\n",
      "   1. Red√©marre l'API: python api/app.py\n",
      "   2. Teste: python test_api.py\n",
      "\n",
      "‚úÖ PROJET COMPLET √Ä 100% !\n",
      "\n",
      "üîß CORRECTION DU LABEL ENCODER\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ Vrai LabelEncoder sauvegard√©\n",
      "‚úÖ API pr√™te avec le vrai LabelEncoder\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üî• R√âENTRA√éNEMENT DU MOD√àLE FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üî• R√âENTRA√éNEMENT DU MOD√àLE LOGISTICREGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================\n",
    "# 1. CHARGEMENT DES DONN√âES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüì¶ 1. CHARGEMENT DES DONN√âES COMPL√àTES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df = pd.read_csv('../data/spam.csv', encoding='latin-1')\n",
    "df = df[['v1', 'v2']]\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "print(f\"‚úÖ Donn√©es charg√©es: {len(df)} messages\")\n",
    "print(f\"   ‚Ä¢ HAM: {sum(df['label'] == 'ham')} messages\")\n",
    "print(f\"   ‚Ä¢ SPAM: {sum(df['label'] == 'spam')} messages\")\n",
    "\n",
    "# Convertir les labels\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# ============================================\n",
    "# 2. NETTOYAGE DU TEXTE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüßπ 2. NETTOYAGE DU TEXTE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Nettoie le texte\"\"\"\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Supprimer URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Supprimer emails\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Supprimer num√©ros de t√©l√©phone\n",
    "    text = re.sub(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]', '', text)\n",
    "    \n",
    "    # Supprimer ponctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Supprimer chiffres\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Supprimer caract√®res sp√©ciaux\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['clean_message'] = df['message'].apply(clean_text)\n",
    "print(\"‚úÖ Texte nettoy√©\")\n",
    "\n",
    "# ============================================\n",
    "# 3. VECTORISATION TF-IDF\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüî§ 3. VECTORISATION TF-IDF\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Cr√©er le vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,\n",
    "    min_df=5,\n",
    "    max_df=0.7,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "# Ajuster et transformer\n",
    "X_tfidf = vectorizer.fit_transform(df['clean_message'])\n",
    "print(f\"‚úÖ TF-IDF cr√©√©: {X_tfidf.shape[1]} features\")\n",
    "\n",
    "# ============================================\n",
    "# 4. FEATURES NUM√âRIQUES (16 features)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüî¢ 4. EXTRACTION DES FEATURES NUM√âRIQUES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "def extract_numeric_features(text):\n",
    "    \"\"\"Extrait 16 features num√©riques\"\"\"\n",
    "    # 1. Longueur\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "    avg_word_length = char_count / max(word_count, 1)\n",
    "    \n",
    "    # 2. Mots suspects de spam\n",
    "    spam_keywords = [\n",
    "        'free', 'win', 'winner', 'won', 'prize', 'cash', \n",
    "        'urgent', 'congratulations', 'claim', 'offer',\n",
    "        'money', 'guaranteed', 'risk', 'limited'\n",
    "    ]\n",
    "    \n",
    "    keyword_features = []\n",
    "    for keyword in spam_keywords[:8]:  # Prendre 8 mots-cl√©s\n",
    "        keyword_features.append(1 if keyword in text.lower() else 0)\n",
    "    \n",
    "    # 3. Ponctuation et majuscules\n",
    "    exclamation_count = text.count('!')\n",
    "    question_count = text.count('?')\n",
    "    upper_case_ratio = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n",
    "    \n",
    "    # 4. Flags\n",
    "    is_long_message = 1 if char_count > 100 else 0\n",
    "    has_punctuation = 1 if ('!' in text or '?' in text) else 0\n",
    "    \n",
    "    # Total: 16 features\n",
    "    features = [\n",
    "        char_count,\n",
    "        word_count,\n",
    "        avg_word_length,\n",
    "        *keyword_features,  # 8 features\n",
    "        exclamation_count,\n",
    "        question_count,\n",
    "        upper_case_ratio,\n",
    "        is_long_message,\n",
    "        has_punctuation\n",
    "    ]\n",
    "    \n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "# Extraire pour tous les messages\n",
    "numeric_features_list = []\n",
    "for text in df['message']:\n",
    "    numeric_features = extract_numeric_features(text)\n",
    "    numeric_features_list.append(numeric_features)\n",
    "\n",
    "X_numeric = np.array(numeric_features_list)\n",
    "X_numeric_sparse = csr_matrix(X_numeric)\n",
    "\n",
    "print(f\"‚úÖ Features num√©riques extraites: {X_numeric.shape[1]} features\")\n",
    "\n",
    "# ============================================\n",
    "# 5. COMBINAISON DES FEATURES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîó 5. COMBINAISON DES FEATURES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Combiner TF-IDF (1000) + Num√©riques (16) = 1016\n",
    "X_combined = hstack([X_tfidf, X_numeric_sparse])\n",
    "y = df['label_num'].values\n",
    "\n",
    "print(f\"‚úÖ Features combin√©es: {X_combined.shape[1]} features total\")\n",
    "print(f\"   ‚Ä¢ TF-IDF: {X_tfidf.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Num√©riques: {X_numeric.shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Cibles: {len(y)}\")\n",
    "\n",
    "# ============================================\n",
    "# 6. SPLIT TRAIN/TEST\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìä 6. SPLIT DES DONN√âES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Split termin√©:\")\n",
    "print(f\"   ‚Ä¢ Train: {X_train.shape[0]} √©chantillons\")\n",
    "print(f\"   ‚Ä¢ Test: {X_test.shape[0]} √©chantillons\")\n",
    "\n",
    "# ============================================\n",
    "# 7. ENTRA√éNEMENT DU MOD√àLE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nü§ñ 7. ENTRA√éNEMENT DU MOD√àLE LOGISTICREGRESSION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Cr√©er et entra√Æner le mod√®le\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # Important car donn√©es d√©s√©quilibr√©es\n",
    "    C=1.0,\n",
    "    solver='liblinear'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Mod√®le entra√Æn√©\")\n",
    "\n",
    "# ============================================\n",
    "# 8. √âVALUATION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìà 8. √âVALUATION DU MOD√àLE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# M√©triques\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"üìä PERFORMANCES:\")\n",
    "print(f\"   ‚Ä¢ Accuracy (train): {train_accuracy:.2%}\")\n",
    "print(f\"   ‚Ä¢ Accuracy (test):  {test_accuracy:.2%}\")\n",
    "print(f\"   ‚Ä¢ Precision:        {precision:.2%}\")\n",
    "print(f\"   ‚Ä¢ Recall:           {recall:.2%}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:         {f1:.2%}\")\n",
    "\n",
    "# Rapport d√©taill√©\n",
    "print(f\"\\nüìã RAPPORT DE CLASSIFICATION:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['HAM', 'SPAM']))\n",
    "\n",
    "# ============================================\n",
    "# 9. SAUVEGARDE DES MOD√àLES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüíæ 9. SAUVEGARDE DES MOD√àLES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Sauvegarder le mod√®le\n",
    "joblib.dump(model, '../models/logistic_regression_model_final.joblib')\n",
    "print(\"‚úÖ Mod√®le sauvegard√©: models/logistic_regression_model_final.joblib\")\n",
    "\n",
    "# Sauvegarder le vectorizer\n",
    "joblib.dump(vectorizer, '../models/tfidf_vectorizer_final.joblib')\n",
    "print(\"‚úÖ Vectorizer sauvegard√©: models/tfidf_vectorizer_final.joblib\")\n",
    "\n",
    "# Sauvegarder l'encoder de labels\n",
    "label_encoder = {'ham': 0, 'spam': 1}\n",
    "joblib.dump(label_encoder, '../models/label_encoder_final.joblib')\n",
    "print(\"‚úÖ Label encoder sauvegard√©: models/label_encoder_final.joblib\")\n",
    "\n",
    "# ============================================\n",
    "# 10. TESTS DE PR√âDICTION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüß™ 10. TESTS DE PR√âDICTION\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "test_messages = [\n",
    "    (\"Congratulations! You won a free iPhone! Call now to claim!\", \"SPAM\"),\n",
    "    (\"Hey, are we still meeting for lunch tomorrow?\", \"HAM\"),\n",
    "    (\"URGENT: Your bank account has been compromised.\", \"SPAM\"),\n",
    "    (\"Don't forget to buy milk on your way home\", \"HAM\"),\n",
    "    (\"FREE entry to win ¬£1000 cash prize. Text WIN now!\", \"SPAM\"),\n",
    "    (\"Meeting rescheduled to 3 PM. See you then.\", \"HAM\")\n",
    "]\n",
    "\n",
    "print(\"üìù Tests de pr√©diction:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for message, expected in test_messages:\n",
    "    # Nettoyer\n",
    "    clean_msg = clean_text(message)\n",
    "    \n",
    "    # TF-IDF\n",
    "    tfidf_features = vectorizer.transform([clean_msg])\n",
    "    \n",
    "    # Features num√©riques\n",
    "    numeric_features = extract_numeric_features(message)\n",
    "    numeric_features_sparse = csr_matrix(numeric_features.reshape(1, -1))\n",
    "    \n",
    "    # Combiner\n",
    "    features = hstack([tfidf_features, numeric_features_sparse])\n",
    "    \n",
    "    # Pr√©dire\n",
    "    pred_num = model.predict(features)[0]\n",
    "    pred_proba = model.predict_proba(features)[0]\n",
    "    \n",
    "    prediction = 'SPAM' if pred_num == 1 else 'HAM'\n",
    "    spam_prob = pred_proba[1]\n",
    "    \n",
    "    # Afficher\n",
    "    print(f\"üì® '{message[:50]}...'\")\n",
    "    print(f\"   ‚Üí Pr√©dit: {prediction} ({spam_prob:.2%})\")\n",
    "    print(f\"   ‚Üí Attendu: {expected}\")\n",
    "    print(f\"   ‚Üí {'‚úÖ CORRECT' if prediction == expected else '‚ùå INCORRECT'}\")\n",
    "    print()\n",
    "\n",
    "# ============================================\n",
    "# 11. MISE √Ä JOUR DE L'API\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüåê 11. MISE √Ä JOUR DE L'API\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Lire le fichier API actuel\n",
    "with open('../api/app.py', 'r', encoding='utf-8') as f:\n",
    "    api_content = f.read()\n",
    "\n",
    "# Remplacer les chemins des mod√®les\n",
    "api_content = api_content.replace(\n",
    "    \"'../models/logistic_regression_model.joblib'\",\n",
    "    \"'../models/logistic_regression_model_final.joblib'\"\n",
    ")\n",
    "api_content = api_content.replace(\n",
    "    \"'../models/tfidf_vectorizer.joblib'\",\n",
    "    \"'../models/tfidf_vectorizer_final.joblib'\"\n",
    ")\n",
    "api_content = api_content.replace(\n",
    "    \"'../models/label_encoder.joblib'\",\n",
    "    \"'../models/label_encoder_final.joblib'\"\n",
    ")\n",
    "\n",
    "# Sauvegarder\n",
    "with open('../api/app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(api_content)\n",
    "\n",
    "print(\"‚úÖ API mise √† jour avec le nouveau mod√®le\")\n",
    "\n",
    "# ============================================\n",
    "# 12. R√âSUM√â FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ R√âENTRA√éNEMENT TERMIN√â !\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä PERFORMANCES FINALES:\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {test_accuracy:.2%}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {f1:.2%}\")\n",
    "\n",
    "print(f\"\\nüìÅ MOD√àLES SAUVEGARD√âS:\")\n",
    "print(f\"   ‚Ä¢ logistic_regression_model_final.joblib\")\n",
    "print(f\"   ‚Ä¢ tfidf_vectorizer_final.joblib\")\n",
    "print(f\"   ‚Ä¢ label_encoder_final.joblib\")\n",
    "\n",
    "print(f\"\\nüöÄ POUR TESTER:\")\n",
    "print(f\"   1. Red√©marre l'API: python api/app.py\")\n",
    "print(f\"   2. Teste: python test_api.py\")\n",
    "\n",
    "print(f\"\\n‚úÖ PROJET COMPLET √Ä 100% !\")\n",
    "# ============================================\n",
    "# üîß CORRECTION DU LABEL ENCODER\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîß CORRECTION DU LABEL ENCODER\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cr√©er un vrai LabelEncoder\n",
    "label_encoder_obj = LabelEncoder()\n",
    "label_encoder_obj.fit(['ham', 'spam'])\n",
    "\n",
    "# Sauvegarder\n",
    "joblib.dump(label_encoder_obj, '../models/label_encoder_final.joblib')\n",
    "print(\"‚úÖ Vrai LabelEncoder sauvegard√©\")\n",
    "\n",
    "# Mettre √† jour l'API\n",
    "with open('../api/app.py', 'r', encoding='utf-8') as f:\n",
    "    api_content = f.read()\n",
    "\n",
    "# Laisser le code tel quel (l'API utilise d√©j√† inverse_transform)\n",
    "with open('../api/app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(api_content)\n",
    "\n",
    "print(\"‚úÖ API pr√™te avec le vrai LabelEncoder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
